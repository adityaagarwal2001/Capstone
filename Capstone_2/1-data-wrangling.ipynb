{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "This notebook is divided into four sections, one for each dataset. Following steps are performed on each section,\n",
    "\n",
    "1. Load dataset\n",
    "2. Data wrangling\n",
    "3. Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.290136Z",
     "start_time": "2018-11-25T17:48:58.497807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import missingno as ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset 1\n",
    "\n",
    "Holiday performance: df_holidays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.589767Z",
     "start_time": "2018-11-25T17:49:01.290136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['List', 'Presidents_day', 'Easter', 'Memorial_day', 'Independence_day', 'Labor_day', 'Thanksgiving', 'Winter_holiday']\n"
     ]
    }
   ],
   "source": [
    "# load holiday performance xls file\n",
    "\n",
    "xls = pd.ExcelFile(r'C:\\Users\\Adi\\Desktop\\Data_Science\\Capstone\\Capstone_2\\Data\\Holidays.xlsx') \n",
    "\n",
    "# print list of all sheets in the file\n",
    "print(xls.sheet_names)\n",
    "\n",
    "# read all sheets from file into dict\n",
    "sheets = {}\n",
    "for sheet in xls.sheet_names:\n",
    "    sheets[sheet] = xls.parse(sheet)\n",
    "\n",
    "# create separate dataframe for holiday dates from first sheet\n",
    "holiday_list = sheets[xls.sheet_names[0]]\n",
    "holiday_list.columns = [x.lower() for x in holiday_list.columns] # set column names to lower case\n",
    "\n",
    "# add holiday name as new column in each sheet    \n",
    "for sheet in xls.sheet_names[1:]: # leave the first sheet as it's a list of holiday dates\n",
    "    sheets[sheet]['Holiday'] = sheet\n",
    "\n",
    "# create df_holidays starting second sheet. first sheet is list of holiday dates\n",
    "df_holidays = sheets[xls.sheet_names[1]]\n",
    "\n",
    "# append remaining sheets in df_holidays\n",
    "for sheet in xls.sheet_names[2:]:\n",
    "    df_holidays = df_holidays.append(sheets[sheet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.597725Z",
     "start_time": "2018-11-25T17:49:01.589767Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correct column names\n",
    "df_holidays_column_names = ['year', 'total_flights', 'dep_ontime', 'dep_delayed', 'dep_cancel', 'arr_ontime', 'arr_delayed', 'arr_div', 'holiday']\n",
    "\n",
    "# drop percentage of total columns. These can be calculated as column over total value\n",
    "df_holidays.drop(columns=['Unnamed: 3', 'Unnamed: 5', 'Unnamed: 7', 'Unnamed: 9', 'Unnamed: 11', 'Unnamed: 13'], inplace=True)\n",
    "\n",
    "# update columns names from list\n",
    "df_holidays.columns = df_holidays_column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.609707Z",
     "start_time": "2018-11-25T17:49:01.597725Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge df_holidays with holiday_list to get date and period\n",
    "df_holidays = df_holidays.merge(holiday_list, on=['holiday', 'year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.641663Z",
     "start_time": "2018-11-25T17:49:01.609707Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70 entries, 0 to 69\n",
      "Data columns (total 12 columns):\n",
      "year               70 non-null int64\n",
      "total_flights      70 non-null object\n",
      "dep_ontime         70 non-null object\n",
      "dep_delayed        70 non-null object\n",
      "dep_cancel         70 non-null object\n",
      "arr_ontime         70 non-null object\n",
      "arr_delayed        70 non-null object\n",
      "arr_div            70 non-null object\n",
      "holiday            70 non-null object\n",
      "date of holiday    70 non-null datetime64[ns]\n",
      "start date         70 non-null datetime64[ns]\n",
      "end date           70 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](3), int64(1), object(8)\n",
      "memory usage: 7.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total_flights</th>\n",
       "      <th>dep_ontime</th>\n",
       "      <th>dep_delayed</th>\n",
       "      <th>dep_cancel</th>\n",
       "      <th>arr_ontime</th>\n",
       "      <th>arr_delayed</th>\n",
       "      <th>arr_div</th>\n",
       "      <th>holiday</th>\n",
       "      <th>date of holiday</th>\n",
       "      <th>start date</th>\n",
       "      <th>end date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>105227</td>\n",
       "      <td>85420</td>\n",
       "      <td>18588</td>\n",
       "      <td>1219</td>\n",
       "      <td>82028</td>\n",
       "      <td>21799</td>\n",
       "      <td>181</td>\n",
       "      <td>Presidents_day</td>\n",
       "      <td>2009-02-16</td>\n",
       "      <td>2009-02-12</td>\n",
       "      <td>2009-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>103994</td>\n",
       "      <td>73339</td>\n",
       "      <td>23249</td>\n",
       "      <td>7406</td>\n",
       "      <td>71299</td>\n",
       "      <td>24935</td>\n",
       "      <td>354</td>\n",
       "      <td>Presidents_day</td>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>2010-02-11</td>\n",
       "      <td>2010-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>98691</td>\n",
       "      <td>74056</td>\n",
       "      <td>22245</td>\n",
       "      <td>2390</td>\n",
       "      <td>72013</td>\n",
       "      <td>24020</td>\n",
       "      <td>268</td>\n",
       "      <td>Presidents_day</td>\n",
       "      <td>2011-02-21</td>\n",
       "      <td>2011-02-17</td>\n",
       "      <td>2011-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>80518</td>\n",
       "      <td>70211</td>\n",
       "      <td>9964</td>\n",
       "      <td>343</td>\n",
       "      <td>69675</td>\n",
       "      <td>10390</td>\n",
       "      <td>110</td>\n",
       "      <td>Presidents_day</td>\n",
       "      <td>2012-02-20</td>\n",
       "      <td>2012-02-16</td>\n",
       "      <td>2012-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>102244</td>\n",
       "      <td>86573</td>\n",
       "      <td>15023</td>\n",
       "      <td>648</td>\n",
       "      <td>85807</td>\n",
       "      <td>15676</td>\n",
       "      <td>113</td>\n",
       "      <td>Presidents_day</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>2013-02-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year total_flights dep_ontime dep_delayed dep_cancel arr_ontime  \\\n",
       "0  2009        105227      85420       18588       1219      82028   \n",
       "1  2010        103994      73339       23249       7406      71299   \n",
       "2  2011         98691      74056       22245       2390      72013   \n",
       "3  2012         80518      70211        9964        343      69675   \n",
       "4  2013        102244      86573       15023        648      85807   \n",
       "\n",
       "  arr_delayed arr_div         holiday date of holiday start date   end date  \n",
       "0       21799     181  Presidents_day      2009-02-16 2009-02-12 2009-02-17  \n",
       "1       24935     354  Presidents_day      2010-02-15 2010-02-11 2010-02-16  \n",
       "2       24020     268  Presidents_day      2011-02-21 2011-02-17 2011-02-22  \n",
       "3       10390     110  Presidents_day      2012-02-20 2012-02-16 2012-02-21  \n",
       "4       15676     113  Presidents_day      2013-02-18 2013-02-14 2013-02-19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final df_holidays\n",
    "print(df_holidays.info())\n",
    "df_holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.657677Z",
     "start_time": "2018-11-25T17:49:01.641663Z"
    }
   },
   "outputs": [],
   "source": [
    "# export dataset\n",
    "\n",
    "df_holidays.to_csv('Dataset_export\\holidays.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset 2\n",
    "\n",
    "Delay causes: df_delay_cause\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:02.847796Z",
     "start_time": "2018-11-25T17:49:01.657677Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(r'C:\\Users\\Adi\\Desktop\\Data_Science\\Capstone\\Capstone_2\\Data\\Delay_cause.csv')\n",
    "\n",
    "# drop empty column\n",
    "df.drop(columns=['Unnamed: 21'], inplace=True)\n",
    "\n",
    "# df_delay_cause with data from 2017 and 2018 only because analysis is for flights starting 2017\n",
    "df_delay_cause = df[(df.year == 2017) | (df.year == 2018)]\n",
    "df_delay_cause.reset_index(inplace=True) # reset index to start from 0\n",
    "\n",
    "# update column names with correct spelling\n",
    "df_delay_cause.columns = ['index', 'year', 'month', 'carrier', 'carrier_name', 'airport',\n",
    "       'airport_name', 'arr_flights', 'arr_del15', 'carrier_ct', 'weather_ct',\n",
    "       'nas_ct', 'security_ct', 'late_aircraft_ct', 'arr_cancelled',\n",
    "       'arr_diverted', 'arr_delay', 'carrier_delay', 'weather_delay',\n",
    "       'nas_delay', 'security_delay', 'late_aircraft_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:02.894957Z",
     "start_time": "2018-11-25T17:49:02.848303Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24195 entries, 0 to 24194\n",
      "Data columns (total 22 columns):\n",
      "index                  24195 non-null int64\n",
      "year                   24195 non-null int64\n",
      "month                  24195 non-null int64\n",
      "carrier                24195 non-null object\n",
      "carrier_name           24195 non-null object\n",
      "airport                24195 non-null object\n",
      "airport_name           24195 non-null object\n",
      "arr_flights            24177 non-null float64\n",
      "arr_del15              24170 non-null float64\n",
      "carrier_ct             24177 non-null float64\n",
      "weather_ct             24177 non-null float64\n",
      "nas_ct                 24177 non-null float64\n",
      "security_ct            24177 non-null float64\n",
      "late_aircraft_ct       24177 non-null float64\n",
      "arr_cancelled          24177 non-null float64\n",
      "arr_diverted           24177 non-null float64\n",
      "arr_delay              24177 non-null float64\n",
      "carrier_delay          24177 non-null float64\n",
      "weather_delay          24177 non-null float64\n",
      "nas_delay              24177 non-null float64\n",
      "security_delay         24177 non-null float64\n",
      "late_aircraft_delay    24177 non-null float64\n",
      "dtypes: float64(15), int64(3), object(4)\n",
      "memory usage: 4.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>carrier</th>\n",
       "      <th>carrier_name</th>\n",
       "      <th>airport</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>arr_flights</th>\n",
       "      <th>arr_del15</th>\n",
       "      <th>carrier_ct</th>\n",
       "      <th>...</th>\n",
       "      <th>security_ct</th>\n",
       "      <th>late_aircraft_ct</th>\n",
       "      <th>arr_cancelled</th>\n",
       "      <th>arr_diverted</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220115</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>Albuquerque, NM: Albuquerque International Sun...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220116</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albany, NY: Albany International</td>\n",
       "      <td>88.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220117</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>AMA</td>\n",
       "      <td>Amarillo, TX: Rick Husband Amarillo International</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220118</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA: Hartsfield-Jackson Atlanta Intern...</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>72.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1.98</td>\n",
       "      <td>65.02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11968.0</td>\n",
       "      <td>4237.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2693.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>4771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220119</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Austin, TX: Austin - Bergstrom International</td>\n",
       "      <td>729.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>47.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>38.06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6816.0</td>\n",
       "      <td>3096.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2088.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  year  month carrier            carrier_name airport  \\\n",
       "0  220115  2017      1      AA  American Airlines Inc.     ABQ   \n",
       "1  220116  2017      1      AA  American Airlines Inc.     ALB   \n",
       "2  220117  2017      1      AA  American Airlines Inc.     AMA   \n",
       "3  220118  2017      1      AA  American Airlines Inc.     ATL   \n",
       "4  220119  2017      1      AA  American Airlines Inc.     AUS   \n",
       "\n",
       "                                        airport_name  arr_flights  arr_del15  \\\n",
       "0  Albuquerque, NM: Albuquerque International Sun...        125.0       31.0   \n",
       "1                   Albany, NY: Albany International         88.0       10.0   \n",
       "2  Amarillo, TX: Rick Husband Amarillo International         24.0        6.0   \n",
       "3  Atlanta, GA: Hartsfield-Jackson Atlanta Intern...       1112.0      204.0   \n",
       "4       Austin, TX: Austin - Bergstrom International        729.0      126.0   \n",
       "\n",
       "   carrier_ct         ...           security_ct  late_aircraft_ct  \\\n",
       "0       16.26         ...                  0.00             10.36   \n",
       "1        4.52         ...                  0.00              4.41   \n",
       "2        1.65         ...                  0.00              2.79   \n",
       "3       72.58         ...                  1.98             65.02   \n",
       "4       47.75         ...                  0.99             38.06   \n",
       "\n",
       "   arr_cancelled  arr_diverted  arr_delay  carrier_delay  weather_delay  \\\n",
       "0            1.0           0.0     1378.0          758.0           21.0   \n",
       "1            1.0           0.0      402.0          171.0            0.0   \n",
       "2            1.0           0.0      419.0           59.0           64.0   \n",
       "3           24.0           6.0    11968.0         4237.0          108.0   \n",
       "4            2.0           0.0     6816.0         3096.0          103.0   \n",
       "\n",
       "   nas_delay  security_delay  late_aircraft_delay  \n",
       "0       95.0             0.0                504.0  \n",
       "1       17.0             0.0                214.0  \n",
       "2      166.0             0.0                130.0  \n",
       "3     2693.0           159.0               4771.0  \n",
       "4     1419.0           110.0               2088.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display df_delay_cause\n",
    "print(df_delay_cause.info())\n",
    "df_delay_cause.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:03.342556Z",
     "start_time": "2018-11-25T17:49:02.894957Z"
    }
   },
   "outputs": [],
   "source": [
    "# export dataset\n",
    "\n",
    "df_delay_cause.to_csv('Dataset_export\\delay_cause.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset 3\n",
    "\n",
    "National performance: df_national_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:03.406461Z",
     "start_time": "2018-11-25T17:49:03.342556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read dataset from xlsx file\n",
    "xls = pd.ExcelFile(r'C:\\Users\\Adi\\Desktop\\Data_Science\\Capstone\\Capstone_2\\Data\\Airline_performance_month_year.xlsx')\n",
    "df = xls.parse('Sheet')\n",
    "\n",
    "# drop empty columns\n",
    "df_national_performance = df.iloc[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:03.426278Z",
     "start_time": "2018-11-25T17:49:03.406461Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283 entries, 0 to 282\n",
      "Data columns (total 9 columns):\n",
      "Rank                           283 non-null int64\n",
      "Year                           283 non-null int64\n",
      "Month                          283 non-null int64\n",
      "Percent On-Time Arrivals       283 non-null float64\n",
      "Percent Late Arrivals          283 non-null float64\n",
      "Percent Cancelled              283 non-null float64\n",
      "Percent Diverted               283 non-null float64\n",
      "Percent On-Time Departures     283 non-null float64\n",
      "Number of Scheduled Flights    283 non-null int64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 20.0 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Percent On-Time Arrivals</th>\n",
       "      <th>Percent Late Arrivals</th>\n",
       "      <th>Percent Cancelled</th>\n",
       "      <th>Percent Diverted</th>\n",
       "      <th>Percent On-Time Departures</th>\n",
       "      <th>Number of Scheduled Flights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "      <td>88.59</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.14</td>\n",
       "      <td>89.03</td>\n",
       "      <td>509540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>88.27</td>\n",
       "      <td>11.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.13</td>\n",
       "      <td>87.93</td>\n",
       "      <td>454162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>87.95</td>\n",
       "      <td>11.07</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.12</td>\n",
       "      <td>89.99</td>\n",
       "      <td>429996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>86.97</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>87.09</td>\n",
       "      <td>486165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>86.85</td>\n",
       "      <td>11.84</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>89.16</td>\n",
       "      <td>527303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Year  Month  Percent On-Time Arrivals  Percent Late Arrivals  \\\n",
       "0     1  2009     11                     88.59                  10.74   \n",
       "1     2  2017     11                     88.27                  11.30   \n",
       "2     3  2002      9                     87.95                  11.07   \n",
       "3     4  2015     10                     86.97                  12.36   \n",
       "4     5  2003      4                     86.85                  11.84   \n",
       "\n",
       "   Percent Cancelled  Percent Diverted  Percent On-Time Departures  \\\n",
       "0               0.54              0.14                       89.03   \n",
       "1               0.31              0.13                       87.93   \n",
       "2               0.86              0.12                       89.99   \n",
       "3               0.50              0.17                       87.09   \n",
       "4               1.20              0.12                       89.16   \n",
       "\n",
       "   Number of Scheduled Flights  \n",
       "0                       509540  \n",
       "1                       454162  \n",
       "2                       429996  \n",
       "3                       486165  \n",
       "4                       527303  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_national_performance.info())\n",
    "df_national_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:36.742471Z",
     "start_time": "2018-11-25T17:49:36.726456Z"
    }
   },
   "outputs": [],
   "source": [
    "# export dataset\n",
    "\n",
    "df_national_performance.to_csv(r'Dataset_export\\national_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset 4\n",
    "\n",
    "Flight performance: frames\n",
    "(from Jan 2017 to Jul 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:45.379123Z",
     "start_time": "2018-11-25T17:49:45.375131Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of years and months to be used throughout the code\n",
    "# data available from Jan 2017 to Jul 2018\n",
    "\n",
    "years = ['2017', '2018']\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:02.893186Z",
     "start_time": "2018-11-25T17:49:45.379123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize empty dictonary which will hold 19 dataframes, Jan 2017 to July 2018\n",
    "frames = {}\n",
    "\n",
    "# read all files using pandas\n",
    "for year in years:\n",
    "    if year == '2017':\n",
    "        for month in months:\n",
    "            path = 'data/' + year + ' ' + month + '.csv'\n",
    "            df = pd.read_csv(path, low_memory=False)\n",
    "            frames[year + month] = df\n",
    "    else:\n",
    "        for month in months[:7]: # dataset available only for first 7 months of 2018\n",
    "            path = 'data/' + year + ' ' + month + '.csv'\n",
    "            df = pd.read_csv(path, low_memory=False)\n",
    "            frames[year + month] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:02.998558Z",
     "start_time": "2018-11-25T17:53:02.924247Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of columns not required for this analysis\n",
    "\n",
    "drop_columns = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DOT_ID_Reporting_Airline', 'IATA_CODE_Reporting_Airline', 'Flight_Number_Reporting_Airline', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac', 'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'DepDelay', 'WheelsOff', 'WheelsOn', 'DepDelayMinutes', 'DepartureDelayGroups', 'ArrDelay', 'ArrDelayMinutes', 'ArrivalDelayGroups', 'CRSElapsedTime', 'ActualElapsedTime', 'Flights', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'AirTime', 'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1Airport', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div1TailNum', 'Div2Airport', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div2TailNum', 'Div3Airport', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div3TailNum', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum', 'Unnamed: 109']\n",
    "\n",
    "# keep columns \n",
    "# 'FlightDate', 'DayOfWeek', 'Reporting_Airline', 'Tail_Number', 'Dest', 'Origin', 'CRSDepTime', 'DepTime'\n",
    "# 'DepDel15', 'DepTimeBlk', 'TaxiOut', 'TaxiIn', 'CRSArrTime', 'ArrTime'\n",
    "# 'ArrDel15', 'ArrTimeBlk', 'Cancelled', 'CancellationCode', 'Diverted', 'Distance'\n",
    "# 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:03.010545Z",
     "start_time": "2018-11-25T17:53:02.998558Z"
    }
   },
   "outputs": [],
   "source": [
    "# fill nan function replaces missing values for high impact columns i.e. departure and arrival time\n",
    "# if column value cannot be missing for this analysis it is categorized as high impact\n",
    "\n",
    "def fill_nan_high(df, strategy='drop'):\n",
    "    \n",
    "    if strategy == 'drop':\n",
    "        \n",
    "        # using strategy drop nan rows\n",
    "        # less than 3% of total data\n",
    "        \n",
    "        df.dropna(subset=['DepTime'], inplace=True)\n",
    "        df.dropna(subset=['ArrTime'], inplace=True)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # replace missing data\n",
    "        # explore more data to find correct groupby condition\n",
    "        \n",
    "        df['DepTime'] = df.groupby(['DoW', 'Reporting_Airline', 'Origin', 'Dest', 'DepTimeBlk'])\\\n",
    "                        ['DepTime'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "        df['ArrTime'] = df.groupby(['DoW', 'Reporting_Airline', 'Origin', 'Dest', 'ArrTimeBlk'])\\\n",
    "                        ['ArrTime'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:03.022527Z",
     "start_time": "2018-11-25T17:53:03.010545Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert columns to int\n",
    "\n",
    "def int_columns(df):\n",
    "    \n",
    "    # list of columns \n",
    "    \n",
    "    int_columns = ['CRSDepTime', 'DepTime', 'DepDel15', 'TaxiOut', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDel15', 'Cancelled', 'Diverted', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "    \n",
    "    for column in int_columns:\n",
    "        df.loc[df[column].notnull(), column] = df.loc[df[column].notnull(), column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:03.030516Z",
     "start_time": "2018-11-25T17:53:03.022527Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_nan(df):\n",
    "\n",
    "    # medium impact columns - missing data can be imputed with mean/median value\n",
    "\n",
    "    nan_columns_medium = ['TaxiOut', 'TaxiIn']\n",
    "\n",
    "    df['TaxiOut'] = df.groupby(['DayOfWeek', 'Origin', 'DepTimeBlk'])['TaxiOut']\\\n",
    "                      .transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "    df['TaxiIn'] = df.groupby(['DayOfWeek', 'Dest', 'ArrTimeBlk'])['TaxiIn']\\\n",
    "                     .transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    # low impact - missing data can be replaced with 0\n",
    "    # value 1 only if flag is valid\n",
    "    \n",
    "    nan_columns_low = ['CancellationCode', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "    \n",
    "    for column in nan_columns_low:\n",
    "        df[column].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:03.038506Z",
     "start_time": "2018-11-25T17:53:03.030516Z"
    }
   },
   "outputs": [],
   "source": [
    "# set datettime columns to correct format\n",
    "\n",
    "def datetime_columns(df):\n",
    "    \n",
    "    # check if flightdate should be converted to datetime\n",
    "    #df['FlightDate']\n",
    "    \n",
    "    time_columns = ['CRSDepTime', 'DepTime', 'ArrTime', 'CRSArrTime']\n",
    "    \n",
    "    for column in time_columns:\n",
    "\n",
    "        # fill with zeros to make 4 digit long       \n",
    "        df.loc[df[column].notnull(), column] = df.loc[df[column].notnull(), column]\\\n",
    "                                                 .astype('str').str.pad(4,'left','0')\n",
    "\n",
    "        # convert 2400 to 0000 i.e. midnight\n",
    "        df.loc[df[column] == '2400', column] = '0000'\n",
    "\n",
    "        # split into hh:mm\n",
    "        df.loc[df[column].notnull(), column] = df.loc[df[column].notnull(), column].str[0:2] + ':' + \\\n",
    "                                               df.loc[df[column].notnull(), column].str[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:03.046496Z",
     "start_time": "2018-11-25T17:53:03.038506Z"
    }
   },
   "outputs": [],
   "source": [
    "# derived columns\n",
    "\n",
    "def column_operations(df):\n",
    "    \n",
    "    # set departure and arrival delay flag 1 for threshold more than 15 minutes\n",
    "    \n",
    "    FMT = '%H:%M'\n",
    "    DepDel15 = df['DepTime'].apply(lambda x: datetime.strptime(x, FMT)) - \\\n",
    "               df['CRSDepTime'].apply(lambda x: datetime.strptime(x, FMT))\n",
    "        \n",
    "    ArrDel15 = df['ArrTime'].apply(lambda x: datetime.strptime(x, FMT)) - \\\n",
    "               df['CRSArrTime'].apply(lambda x: datetime.strptime(x, FMT))\n",
    "    \n",
    "    # condition if time difference cant be negative i.e. clock has to cross midnight\n",
    "    # if tdelta.days < 0:\n",
    "    #     tdelta = timedelta(days=0, seconds=tdelta.seconds, microseconds=tdelta.microseconds)    \n",
    "        \n",
    "    df['DepDel15'] = np.where(DepDel15.astype('timedelta64[m]') > 15, 1, 0)\n",
    "    df['ArrDel15'] = np.where(DepDel15.astype('timedelta64[m]') > 15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:53:03.050490Z",
     "start_time": "2018-11-25T17:53:03.046496Z"
    }
   },
   "outputs": [],
   "source": [
    "# how to subplot missing value matrix for all frames?\n",
    "# ms.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T18:05:49.200027Z",
     "start_time": "2018-11-25T17:53:03.050490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "df_list_cancelled = []\n",
    "\n",
    "for key, value in frames.items():\n",
    "    \n",
    "    # insert wrangle functions here\n",
    "    \n",
    "    df = frames[key].loc[frames[key].Cancelled == 0, : ]            # split frames for non cancelled flights\n",
    "    df_cancelled = frames[key].loc[frames[key].Cancelled == 1, : ]  # split frames for cancelled flights\n",
    "    \n",
    "    df.drop(columns=drop_columns, inplace=True) # drop unwanted columns\n",
    "    df_cancelled.drop(columns=drop_columns, inplace=True)\n",
    "    \n",
    "    fill_nan_high(df, strategy='drop')          # fill nan for high impact columns \n",
    "    int_columns(df)                             # convert numberic columns to int\n",
    "    fill_nan(df)                                # fill nan for medium and low impact columns\n",
    "    datetime_columns(df)                        # correct datetime format\n",
    "    column_operations(df)                       # update delay flags\n",
    "    \n",
    "    # check for null values\n",
    "    \n",
    "    #null = df.isnull().any().any()                          \n",
    "    #print('Missing values in ' + key + ': ' + str(null))\n",
    "    \n",
    "    # create list of all dataframes\n",
    "    path = 'Dataset_export/' + key + '.csv'\n",
    "    df.to_csv(path, index=False)\n",
    "    \n",
    "    #df_list.append(df)\n",
    "    df_list_cancelled.append(df_cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T18:05:49.324439Z",
     "start_time": "2018-11-25T18:05:49.200027Z"
    }
   },
   "outputs": [],
   "source": [
    "# concat list of dataframes to df_flights\n",
    "\n",
    "#df_flights = pd.DataFrame()\n",
    "df_cancelled = pd.DataFrame()\n",
    "\n",
    "#df_flights = pd.concat(df_list, ignore_index=True)\n",
    "df_cancelled = pd.concat(df_list_cancelled, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T18:05:51.381288Z",
     "start_time": "2018-11-25T18:05:49.324439Z"
    }
   },
   "outputs": [],
   "source": [
    "# export dataset\n",
    "\n",
    "#df_flights.to_csv('Dataset_export\\dataset_4.csv', index=False)\n",
    "df_cancelled.to_csv('Dataset_export\\cancelled_flights.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
